![Lastify](/images/lastify_logo.png)
>*A novel approach towards personalized playlist generation based on a user's preferences and listening history.*

# Intro
I first started using [Last.fm](https://last.fm) over nine years ago, as I was interested in keeping track of my music listening history. While I now faintly recall the red “a” appearing in the menu bar, I remember using it to journal my iTunes plays in a process called “scrobbling.”  Fast forward nine years, to shortly after passing the 100,000 scrobble mark, I realized I had a large set of personalized listening data that I was interested in analyzing and exploring. Analyzing to get some general statistics as to my most listened to artists ([Flying Lotus](https://www.youtube.com/watch?v=yK-VuOn1rgs)), and tracks ([DDD by Machinedrum](https://www.youtube.com/watch?v=A2O-Ggo7yoo)), amongst other musical superlatives. And exploring to see what patterns emerged, and if said patterns could help me learn about myself in new ways.

![Figure 1](/images/Figure1.png)
![Figure 2](/images/Figure2.png)

After pouring the initial dataset into Tableau and generating some pretty diagrams (see Fig. 1-2 above), I started to recognize the potential of this data set. I realized that I could use this information to analyze my listening habits, and in turn predict what type of music I would like to listen to at any given time. I decided to combine this data with [Spotify’s Web API](https://developer.spotify.com/) to extract audio features from the songs I have listened to, and determine which audio features were most important at a given time, and then construct playlists of songs based on the parameters of said features.

# Getting started (not really 100k scrobbles)
Seeing that I was well past the 100k scrobble mark, my first question was how do I access this data? A quick google search directed me to [pylast](https://github.com/pylast/pylast), a python package that interfaces with Last.fm. I set up my Last.fm [API account](https://www.last.fm/api), and started exploring what was available to me. The `get_recent_tracks` function returns a list of tracks played in sequential order from the specified start and stop dates. Setting the limit to None, and having the start and end points set to None returns a list of all tracks played. Approximately 4,000 scrobbles had no timestamp (timestamp = 0), which were discarded, leaving me with around 85,000 scrobbles to work with. This remaining list of scrobbles contains the artist, track name, album name, and [Unix timestamp](https://en.wikipedia.org/wiki/Unix_time). This data is then fed into a PostgreSQL table labeled `lastFM`.

**Note**: There is about a 20,000 scrobble difference between what I can see using the API (~90,000), and the number of scrobblems associated with [my account](https://www.last.fm/user/dmatica) (109,000). This has been observed [elsewhere](https://getsatisfaction.com/lastfm/topics/scrobbles-count-in-library-differs-from-scrobbles-count-in-overview), and is speculated to be attributed to iTunes uploading duplicate scrobbles.

# Filtering and retrieving audio features
While Last.fm informs you when you initially start the track, it does not inform you when the track is stopped or finished. This means that partial plays, even when the track is started over after a couple of seconds counts as multiple listens. To account for these, I set a 30 second filter, where I removed tracks whose play length before the next track played was less than 30 seconds, although a more precise filter could undoubtedly be used.

![Figure 3](/images/Figure3.png)
>*Figure 3: Track filtering steps*

Once the tracks in the table have been filtered for presumed play length, a separate table was made, containing only unique tracks from this list.  Using Spotify’s API, a search was performed to identify songs in Spotify’s database by artist and track name, and a Spotify ID was appended to the table.  From there, the tracks with a Spotify ID were checked for audio features using the `audio_features` function.

Spotify performs a proprietary [audio analysis](https://developer.spotify.com/documentation/web-api/reference/tracks/get-audio-features/) on the tracks, identifying certain features. This includes track length, tempo, key, mode, time signature, loudness, acousticness (likelihood track is acoustic), danceability (how danceable the track is), energy (general gauge of track loudness and speed), instrumentalness (whether or not the track is instrumental only), liveness (if there is an audience presence on the track), speechiness (determines if the track is spoken word), and valence (conveyance of musical positiveness). See Figure 4 below for an example of audio features output.

![Figure 4](/images/Figure4.png)
>*Figure 4: Example output audio features from Spotify

# Constructing a model to get some recommendations
With the acquisition of the audio features, we now have a time series dataset of different quantitative listening preferences that we can model. By choosing the day-of-week and time-of-day, we use a binary classifier (0, 1) for tracks played on that day either during that time (1) or not during that time (0) and employ a logistic regression to identify the most important audio features for the given day-of-week and time-of-day. The top 4 features are then fed as seed values into [Spotify’s Get Recommendations function](https://developer.spotify.com/documentation/web-api/reference/browse/get-recommendations/), using the 25th, 50th, and 75th percentiles as the minimum, target, and maximum values for each feature. This function also requires an input as a reference to base the recommendations on, either a genre, artist, track. For this, I included a dropdown menu with all 126 genres in Spotify to choose from. Future implementations will allow to search for an artist or track of interest, or sample from the most listened to artists or tracks during that day-of-week/ time-of-day. Once the track recommendations are made, this can then be saved as a playlist to the user’s account, by typing in a name for the playlist, and choosing to either make the playlist public or private. Figure 5 below is a ‘Detroit-techno’ playlist I made recently, which out of 10 tracks, I ended up adding 5 tracks to my library.

![Figure 5](/images/Figure5.png)
>*Figure 5: Sample playlist generated using Lastify (added 5/10 tracks to library)

# Things to consider
In developing this, I have noticed several things to take into consideration when running this. Firstly, on the Last.fm front, disregarding the issue with lost scrobbles and scrobbles with a timestamp of 0, based on how Last.fm works, there is no information about if a song was completed, or if it was stopped early. The only indicator available is to look at the differences in timestamp between tracks. It also does not tell you the track number of the song scrobble. This becomes problematic in the instances where an album has the same title for all tracks. Additionally, as mentioned earlier on, not all songs are in Spotify’s library, which may bias the feature selection process. Finally, this does not include all forms of listening, which can include, but is not limited to physical formats (cassette, CD, vinyl), listening to the radio, going to concerts, or listening on other digital platforms such as [Amazon Music](https://music.amazon.com), [Google Play](https://play.google.com/music/), [SoundCloud](https://soundcloud.com/), [YouTube](https://youtube.com/), [Bandcamp](https://bandcamp.com/), etc. These can be manually entered as scrobbles to Last.fm but is a time-consuming and tedious process.

# Things to improve
In future iterations, I would like to expand this dataset, by merging with other timeseries data to test out some hypothesis. For example, I would like to include historical weather information as well as mood values in this dataset to test out my hypothesis that weather and mood impact my listening habits. I would also like to include other metadata, such as when I attend concerts, when I see movies to revisit the soundtrack or score, and when I’m traveling. I would also like to group my listening to either desktop or mobile listening.
